{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Data API v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# api_key is stored in config.py\n",
    "import config\n",
    "import networkx as nx\n",
    "\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Youtube Search (query, n)\n",
    "    Returns list of channel dictionaries\n",
    "### 2 - Youtube Channel List\n",
    "    Returns details on a specific channel\n",
    "#### A - Request channel details (channelId)\n",
    "    Returns a json dictionary for a specific channel Id\n",
    "#### B - Run Channel List (list of channelIds)\n",
    "    Returns a list of dictionaries per channel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search method iterating using tokens to get more than 50 results. \n",
    "\n",
    "Uses requests to grab type=channel, part=snippet, order=?;\n",
    "\n",
    "Creates an empty list, extends the list with the json's reponse items (50 at a time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to to return a list of maxResults parameter for each api request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For a given number of requests and a specified batch_size, function will return a list of maxResults. \n",
    " \n",
    " For example: (123, 50) returns [50,50,23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_max_result_list(n, batch_size):\n",
    "    '''Function to return a list of max results parameters for a specific number of requests and batch_sizes.\n",
    "    \n",
    "    For example: (123,50) returns [50,50,23]'''\n",
    "    # Logic to determine maxResults parameter\n",
    "    if n%50 == 0:\n",
    "        request_size_list = [batch_size]*(n//batch_size)\n",
    "    # Determine a list of request sizes []\n",
    "    else:\n",
    "        request_size_list = [batch_size]*(n//batch_size) + [n%batch_size]\n",
    "    return request_size_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to request a youtube search response for a given query and number of requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns a list of dictionaries, each dictionary represents a specific channel and their subsequent details.<br>\n",
    "Also create a channelid_list which comes from ```CHANNEL_LIST[0]['id']```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for channels by a specific query\n",
    "def youtube_request_search_channels(query, n):\n",
    "    '''Returns a list of n channels that match the query.\\n\n",
    "    Uses /youtube/v3/search'''\n",
    "    \n",
    "    request_size_list = determine_max_result_list(n,50)\n",
    "        \n",
    "    # Empty list to store 50 items from each response\n",
    "    channel_list = list()\n",
    "    \n",
    "    # Instantiate nextPageToken, when '' method interprets null\n",
    "    nextPageToken = ''\n",
    "\n",
    "\n",
    "    for request_size in request_size_list:\n",
    "        \n",
    "        # Create request object\n",
    "        resp = requests.get(\n",
    "            'https://www.googleapis.com/youtube/v3/search',\n",
    "            params=dict(part='snippet', \n",
    "                        type='channel',\n",
    "                        maxResults=request_size,\n",
    "                        pageToken=nextPageToken,\n",
    "                        q=query,\n",
    "                        key=config.api_key)\n",
    "        )\n",
    "        assert resp.ok\n",
    "        nextPageToken = json.loads(resp.content)['nextPageToken']\n",
    "        channel_list.extend(json.loads(resp.content)['items'])\n",
    "        #print(len(set(channel['id']['channelId'] for channel in channel_list)))\n",
    "    return channel_list\n",
    "#CHANNEL_LIST = youtube_request_search_channels('Minecraft',23)\n",
    "\n",
    "# Extract Channel Ids from the list of dictionaries\n",
    "#CHANNELID_LIST = [channel['snippet']['channelId'] for channel in CHANNEL_LIST]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to request details on a list of channelIds\n",
    "\n",
    "Returns a list of channel_resp json dictionaries stored in ```json.content['items']``` across all json responses (if requesting a list larger than 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get channel details and snippet\n",
    "def youtube_request_channel_list(channelid_list):\n",
    "    \n",
    "    # Check for non-unique elements\n",
    "    if len(channelid_list) != len(set(channelid_list)):\n",
    "        print(\"There are non-unique elements in this list\")\n",
    "        \n",
    "    # Determine request size list\n",
    "    request_size_list = determine_max_result_list(len(set(channelid_list)),50)\n",
    "\n",
    "    # Instantiate channel response list\n",
    "    channel_resp_list = []\n",
    "    \n",
    "    # Set the start_index to 0\n",
    "    start_index = 0\n",
    "    # Loop \n",
    "    for request_size in request_size_list:\n",
    "        \n",
    "        # Debug\n",
    "        #print(request_size_list, request_size, start_index, start_index+request_size)\n",
    "        \n",
    "        resp = requests.get(\n",
    "            'https://www.googleapis.com/youtube/v3/channels',\n",
    "            params=dict(part='contentDetails, snippet, statistics,\\\n",
    "                        brandingSettings, topicDetails, status, id, contentOwnerDetails',\n",
    "                    id=channelid_list[start_index:start_index+request_size],\n",
    "                    maxResults=50,\n",
    "                    key=config.api_key)\n",
    "        )\n",
    "        # Increase the start_index\n",
    "        start_index += request_size\n",
    "        \n",
    "        # Extend channel response list\n",
    "        channel_resp_list.extend(json.loads(resp.content)['items'])\n",
    "        \n",
    "    return channel_resp_list\n",
    "#CHANNEL_RESP = youtube_request_channel_list(CHANNELID_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to flatten dictionary nesting of channel resp for dataframe format\n",
    "\n",
    "Returns a list of dictionaries where each key in the dictionary maps to a column of interest.<br>\n",
    "As input takes a list of dictionaries where each dictionary is a specific 'item' from the original json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_channel_details(channel_resp):\n",
    "    # Instantite empty channels details list for new dictionary format\n",
    "    channel_details_list = list()\n",
    "    \n",
    "    # Loop over each channel's json dictionary in details_list\n",
    "    for channel in channel_resp:\n",
    "        # Instantiate new details dictionary; in series update the dictionary to include relevant details\n",
    "        channel_details_dict = {}\n",
    "        channel_details_dict.update(dict(id=channel['id']))\n",
    "        channel_details_dict.update(channel['snippet'])\n",
    "        channel_details_dict.update(channel['contentDetails'])\n",
    "        #channel_details_dict.update(channel['topicDetails'])\n",
    "        channel_details_dict.update(channel['status'])\n",
    "        channel_details_dict.update(channel['statistics'])\n",
    "        channel_details_dict.update(channel['brandingSettings']['channel'])\n",
    "        \n",
    "        # Append the added channel's new dictionary format to channel details list\n",
    "        channel_details_list.append(channel_details_dict)\n",
    "    return channel_details_list\n",
    "\n",
    "#CHANNEL_DETAILS_LIST = extract_channel_details(CHANNEL_RESP)\n",
    "\n",
    "# Insert list of dictionaries into pandas dataframe\n",
    "#df = pd.DataFrame(CHANNEL_DETAILS_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YouTube Channel Details by Search\n",
    "\n",
    "Returns a details list of channels for a specific search query and number of requested results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def youtube_channel_details_by_search(query, n):\n",
    "    '''Returns a details list of channels for a specific search query and number of requested results.'''\n",
    "    # Request n number of channels from a youtube search query\n",
    "    channel_list = youtube_request_search_channels(query,n)\n",
    "\n",
    "    # Retrieve Channel Ids from the list of dictionaries\n",
    "    channelid_list = [channel['snippet']['channelId'] for channel in channel_list]\n",
    "\n",
    "    # Request details for all channels in a list of channelIds\n",
    "    channel_response = youtube_request_channel_list(channelid_list)\n",
    "\n",
    "    # Extract channel details to a list of dictionaries for pandas\n",
    "    channel_details_list = extract_channel_details(channel_response)\n",
    "    \n",
    "    return extract_channel_details(channel_response)\n",
    "\n",
    "CHANNEL_DETAILS_LIST = youtube_channel_details_by_search(\"corridor digital\", 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request n number of channels from a youtube search\n",
    "CHANNEL_LIST = youtube_request_search_channels('Corridor Digital',20)\n",
    "\n",
    "# Retrieve Channel Ids from the list of dictionaries\n",
    "CHANNELID_LIST = [channel['snippet']['channelId'] for channel in CHANNEL_LIST]\n",
    "\n",
    "# Request details from each channel\n",
    "CHANNEL_RESP = youtube_request_channel_list(CHANNELID_LIST)\n",
    "\n",
    "# Extract channel details to a list of dictionaries for pandas\n",
    "CHANNEL_DETAILS_LIST = extract_channel_details(CHANNEL_RESP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "youtube_channel_details_by_network([CHANNEL_RESP[9]],2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Youtube Channel Details by Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def youtube_channel_details_by_network(channelid_list, max_degree):\n",
    "    \n",
    "    # get a response for the list of channel Ids\n",
    "    channel_resp = youtube_request_channel_list(channelid_list)\n",
    "    \n",
    "    # Instantiate the output, a list of dictionaries, each dict represents a channel\n",
    "    network_channels_resp = []\n",
    "    \n",
    "    # Add our origin channel responses\n",
    "    network_channels_resp.extend(channel_resp)\n",
    "    \n",
    "    # Instantiate a neighbors channel response\n",
    "    neighbors_channels_resp = channel_resp\n",
    "    \n",
    "    # Loop over each degree of separate (breadth first search)\n",
    "    for degree in range(1,max_degree+1):\n",
    "        \n",
    "        # Extract a list of featured channels ids\n",
    "        neighbors_channels_list = extract_featured_channels(neighbors_channels_resp)\n",
    "        \n",
    "        # Request channel details from Youtube using list of channel ids\n",
    "        neighbors_channels_resp = youtube_request_channel_list(neighbors_channels_list)\n",
    "        \n",
    "        # Add n-degree channel details response\n",
    "        network_channels_resp.extend(neighbors_channels_resp)\n",
    "    \n",
    "    return network_channels_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_featured_channels(channel_response):\n",
    "    ''' Function to extract a set of featured channelIds from a list of channelIds'''\n",
    "    \n",
    "    featured_channels_list = list()\n",
    "    channels_wo_features_count = 0\n",
    "    for channel in channel_response:\n",
    "\n",
    "        if 'featuredChannelsUrls' in channel['brandingSettings']['channel']:\n",
    "            featured_channels_list.extend(channel['brandingSettings']['channel']['featuredChannelsUrls'])\n",
    "        else:\n",
    "            channels_wo_features_count +=1\n",
    "    print(f'{len(set(featured_channels_list))} neighbors; {channels_wo_features_count} out of {len(channel_response)} channels do not feature channels')\n",
    "    return list(set(featured_channels_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary comprehension to create channelId:featuredChannelUrls data structure\n",
    "CHANNEL_NETWORK = {channel['id']:channel['featuredChannelsUrls'] if 'featuredChannelsUrls' in channel.keys() else [] for channel in CHANNEL_DETAILS_LIST}\n",
    "\n",
    "# Dict Comp to create channelId:Channelname data structure\n",
    "CHANNEL_NAMES = {channel['id']:channel['title'] if 'title' in channel.keys() else '' for channel in CHANNEL_DETAILS_LIST}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_channels(channel_details_list):\n",
    "    \n",
    "    # Dictionary comprehension to create channelId:featuredChannelUrls data structure\n",
    "    channel_network = {channel['id']:channel['featuredChannelsUrls'] \\\n",
    "                   if 'featuredChannelsUrls' in channel.keys() else [] \\\n",
    "                   for channel in channel_details_list}\n",
    "\n",
    "    # Dict Comp to create channelId:Channelname data structure\n",
    "    channel_names = {channel['id']:channel['title'] \\\n",
    "                 if 'title' in channel.keys() else '' \\\n",
    "                 for channel in channel_details_list}\n",
    "    \n",
    "    G = nx.DiGraph(channel_network)\n",
    "    plt.figure(figsize = (12,12))\n",
    "    nx.draw_networkx(G,\n",
    "                 with_labels=True,\n",
    "                 labels=channel_names,\n",
    "                 font_size=12, font_color = 'red')\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_channels(channel_network, channel_names):\n",
    "    \n",
    "    G = nx.DiGraph(channel_network)\n",
    "    plt.figure(figsize = (12,12))\n",
    "    nx.draw_networkx(G,\n",
    "                 with_labels=True,\n",
    "                 labels=channel_names,\n",
    "                 font_size=12, font_color = 'red')\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = graph_channels(CHANNEL_NETWORK, CHANNEL_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_page_rank():\n",
    "    A = nx.adjacency_matrix(G)\n",
    "    n, _ = A.shape\n",
    "    v0 = np.ones(n) / n\n",
    "    for i in range(20):\n",
    "        v1 = A @ v0\n",
    "        v1 /= v1.sum(0)\n",
    "        print(np.linalg.norm(v1 - v0))\n",
    "        v0 = v1\n",
    "    return v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V1 = simple_page_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNELIDS = list(G.nodes().keys())\n",
    "vector = pd.Series(data = V1, index = CHANNELIDS)\n",
    "DF['v1'] = DF['id'].map(lambda x:vector[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(CHANNELIDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[['title','id','subscriberCount','viewCount','v1','featuredChannelsCount']].sort_values('v1', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connected Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "def run():\n",
    "    sizes = []\n",
    "    ccs = []\n",
    "    for cc in nx.connected_components(G.to_undirected()):\n",
    "        ccs.append(cc)\n",
    "        sizes.append(len(cc))\n",
    "    print(sorted(sizes))\n",
    "    return ccs#collections.Counter(sizes)\n",
    "\n",
    "CCS = run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,12))\n",
    "nx.draw_networkx(G.subgraph(max(nx.connected_components(G.to_undirected()), key=len)),\n",
    "                 with_labels=False)\n",
    "                 #labels=CHANNEL_NAMES,\n",
    "                 #font_size=12, font_color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw_networkx(G.subgraph(max(nx.connected_components(G.to_undirected()), key=len)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(channel_details_list):\n",
    "    df = pd.DataFrame(channel_details_list)\n",
    "    df['videoCount'] = df['videoCount'].map(lambda x: int(x))\n",
    "    df['commentCount'] = df['commentCount'].map(lambda x: int(x))\n",
    "    df['viewCount'] = df['viewCount'].map(lambda x: int(x))\n",
    "    df['subscriberCount'] = df['subscriberCount'].map(lambda x: int(x))\n",
    "    df['featuredChannelsCount'] = df['featuredChannelsUrls'].apply(lambda x: 0 if type(x) == float else len(x))\n",
    "    return df\n",
    "\n",
    "features = ['id','title','description','customUrl','publishedAt','country','isLinked', 'viewCount', 'commentCount', 'subscriberCount',\n",
    "           'hiddenSubscriberCount','keywords','showRelatedChannels','featuredChannelsUrls', 'featuredChannelsCount']\n",
    "\n",
    "DF = create_dataframe(CHANNEL_DETAILS_LIST)\n",
    "DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF[features].sort_values(by='subscriberCount', ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(DF['subscriberCount'].map(lambda x: np.log(x+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(DF['viewCount'].map(lambda x: np.log(x+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(DF['subscriberCount'], DF['viewCount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(DF['title'], DF['subscriberCount'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
